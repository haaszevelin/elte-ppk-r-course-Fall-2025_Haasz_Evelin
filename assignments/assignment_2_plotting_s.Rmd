---
title: 'Assignment 2: Data visualization'
author: "Tamas Nagy"
output: html_document
editor_options: 
  chunk_output_type: console
---

You will have to create 3 plots based on the datasets and instructions detailed below. You will find the plots themeselves in the `assignments/assignment_2_plots`. Your task is to write the code that will reproduce the plots as closely as possible.

# Skills needed to solve this assignment

-   Using R and RStudio, reading data
-   Reporting using RMarkdown
-   Using Git and Github (for submitting the task)
-   Data manipulation (e.g. dplyr, tidyr), and working with factors (forcats)
-   Data visuzlization (ggplot2)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(tidytuesdayR)
library(ggplot2)
```

## Task 1: Climbing expeditions

```{r}
original_expeditions <- read.csv("C:/Users/Haász Evelin/Downloads/expeditions.csv")
```

The 2020-09-22 TidyTueday datasets are about climbing expeditions. From the three datasets, use the "expeditions". Reproduce the plot below! Notice a few things:

-   Use `forcats::fct_lump()` to get the 15 most frequent peaks, and drop the "Other" category.
-   The bars are ordered by the sum of all expeditions (use `fct_reorder()`).
-   The bar colors use the viridis palette and light theme.

```{r}
library(forcats)
library(viridis)

# counting top 15 peaks
top_peaks_names <- original_expeditions %>%
  count(peak_name, sort = TRUE) %>%
  slice_max(n, n = 15) %>%
  pull(peak_name)

# filtering data for top 15 peaks
top_peaks_data <- original_expeditions %>%
  filter(peak_name %in% top_peaks_names)

# counting expeditions per peak per season
top_peaks_summary <- top_peaks_data %>%
  group_by(peak_name, season) %>%
  summarise(n = n(), .groups = "drop")

# computing total expeditions per peak and reorder factor
top_peaks_summary <- top_peaks_summary %>%
  group_by(peak_name) %>%
  mutate(total = sum(n)) %>%
  ungroup() %>%
  mutate(peak_name = fct_reorder(peak_name, total))

# creating the plot
ggplot(top_peaks_summary, aes(x = peak_name, y = n, fill = season)) +
  geom_col() +
  scale_fill_viridis_d(option = "D") +  # discrete palette for seasons
  coord_flip() +
  theme_light() +
  labs(
    title = "The 15 most popular peaks stacked by season of expedition",
    x = "",
    y = "Number of expeditions",
    fill = "Season"
  ) +
  theme(
    plot.title = element_text(size = 18, hjust = 0.5)
  )
```

## Task 2: PhDs awarded

```{r}
original_phd_by_field <- read.csv("C:/Users/Haász Evelin/Downloads/phd_by_field.csv")
```

The 2019-02-19 TidyTueday dataset is about phd-s awarded by year and field. There is only one dataset, it is called `phd_by_field`. Reproduce the plot below!

Notes:

-   First you have to aggregate the data to count all phd-s by broad fields.
-   To make the x axis breaks pretty, use `scales::pretty_breaks()`, to make the y axis labels comma formatted, use `scales::comma_format()`.
-   The line size is 1.2, the colors are from the brewer "Dark2" palette. The theme is set to minimal.

```{r}
library(scales)
library(RColorBrewer)

# counting total phds by broad fields
phd_summary <- original_phd_by_field %>%
  group_by(year, broad_field) %>%
  summarize(total_phds = sum(n_phds, na.rm = TRUE), .groups="drop")
phd_summary

# creating the plot
ggplot(phd_summary, aes(x = year, y = total_phds, color = broad_field)) +
  geom_line(size = 1.2) +
  scale_x_continuous(breaks = pretty_breaks()) +
  scale_y_continuous(labels = comma_format()) +
  scale_color_brewer(palette = "Dark2") +
  theme_minimal() +
  labs(title = "Number of awarded Ph. D.-s in the US by year",
       x = "",
       y = "",
       color = "broad_field") +
  theme(plot.title = element_text(size = 18, hjust = 0.5))
```

## Task 3: Commute in the US

The 2019-11-05 TidyTueday dataset is about commuting to work in each city in the US by bike or on foot. There is only one dataset, it is called `commute`. Reproduce the plot below!

```{r}
original_commute <- read.csv("C:/Users/Haász Evelin/Downloads/commute.csv")
```

Notes:

-   First you have to aggregate the data to count all commutes by state.
-   Both axis scales are log transformed and the labels comma formatted, using `scales::comma_format()`
-   The point size is 2, . The theme is set to light.

```{r}
# aggregating commutes by state and mode
commutes_by_state <- original_commute %>%
  group_by(state, mode) %>%
  summarise(total_commutes = sum(n, na.rm = TRUE), .groups = "drop") %>%
  pivot_wider(names_from = mode, values_from = total_commutes, values_fill = 0)

# adding state region info and abbreviations
commutes_by_state <- commutes_by_state %>%
  left_join(
    tibble(
      state = state.name,
      region = state.region,
      abbrev = state.abb
    ),
    by = "state"
  )

# plotting the data
ggplot(commutes_by_state, aes(x = Walk, y = Bike)) +
  geom_point(aes(color = region), size = 2) +      
  geom_text(aes(label = abbrev), color = "black", vjust = -0.5, size = 3) +  
  scale_x_log10(labels = comma_format()) +
  scale_y_log10(labels = comma_format()) +
  theme_light() +
  labs(
    title = "Number of people walking vs. biking to work in each US state",
    x = "Number of people walking to work (log N)",
    y = "Number of people biking to work (log N)",
    color = "Region") +
    theme(plot.title = element_text(size = 18, hjust = 0.5))
```
